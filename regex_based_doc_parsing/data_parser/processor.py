import json
import re
import time
from pathlib import Path
from typing import Dict, List, Type

# ê°œë³„ íŒŒì„œ í´ë˜ìŠ¤ import (ë‹¹ì‹ ì´ ì •ì˜í•œ íŒŒì„œë“¤)
from regex_based_doc_parsing.data_parser.parsers.court_parser import CourtParser
from regex_based_doc_parsing.data_parser.parsers.paper_parser import PaperParser
from regex_based_doc_parsing.data_parser.parsers.prec_parser import PrecParser
from regex_based_doc_parsing.data_parser.parsers.paper_parser import get_filtered_text 
from regex_based_doc_parsing.data_parser.parsers.openai_parser import OpenAIParser

# íŒŒì„œ íƒ€ì… ë§¤í•‘
PARSER_REGISTRY: Dict[str, Type] = {
    "PrecService": PrecParser,
    "paper": PaperParser,
    "default": CourtParser,
    "OpenAI": OpenAIParser
}

# íŒŒì„œ ì„ íƒ ë¡œì§
def select_parser(data: Dict, source_folder: str) -> Type:
    if "openai" in source_folder.lower():
        return PARSER_REGISTRY["OpenAI"]()

    elif "PrecService" in data:
        return PARSER_REGISTRY["PrecService"]()
    elif "info" in data and "body" in data:
        return PARSER_REGISTRY["paper"]()
    else:
        return PARSER_REGISTRY["default"]()

# --------------------------- ë²•ë¥  ë°ì´í„° ì²˜ë¦¬ -------------------------------------------------
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
# def process_all(root_folder: Path, output_folder: Path, num_files: int = None, prefix_code: str = "05") -> None:
#     start_time = time.time()
#     output_folder.mkdir(parents=True, exist_ok=True)

#     # ğŸ“‚ ì¤‘ê°„ ì €ì¥ í´ë” (ë¯¼ì‚¬ JSON ì €ì¥ìš©)
#     mid_json_folder = Path(r"C:\Users\megan\onestone\BOAZ_Data_preprocess_logics\regex_based_doc_parsing\data_\json_data\í˜•ì‚¬\set1")
#     mid_json_folder.mkdir(parents=True, exist_ok=True)

#     counter = 1  # ID ë¶€ì—¬ìš©
#     processed_files = 0  # â¬…ï¸ ì²˜ë¦¬í•œ íŒŒì¼ ìˆ˜
    
#     for file in sorted(root_folder.glob("**/*"))[:num_files]:
#         if file.suffix == ".pdf":
#                 data = get_filtered_text(str(file))
#                  # ì¤‘ê°„ JSON ì €ì¥
#                 mid_json_path = mid_json_folder / (file.stem + ".json")
#                 mid_json_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
#                 print(f"ğŸ’¾ ì¤‘ê°„ JSON ì €ì¥ ì™„ë£Œ: {mid_json_path}")
#         elif file.suffix == ".json":
#                 data = json.loads(file.read_text(encoding="utf-8"))
#         else:
#             print(f"âš ï¸ Unsupported file skipped: {file.name}")
#             continue

#         parser = select_parser(data)
#         records = parser.extract_and_split(data)

#         for seq, rec in enumerate(records, start=1):
#             rec["id"] = f"sample_{prefix_code}_000_{counter:06d}"
#             rec["sequence"] = f"{seq:04d}"

#             # ğŸ”¹ ë¬¸ì¥ í´ë¦°ì—…
#             rec["sentence"] = re.sub(r"[\r\n\u2028\u2029\u000b\u000c]+", " ", rec["sentence"]).strip()
#             rec["sentence"] = re.sub(r"\s{2,}", " ", rec["sentence"])

#             counter += 1

#         # ì €ì¥
#         out_name = file.stem + ".json"
#         out_path = output_folder /out_name
#         print(f"ì €ì¥ ê²½ë¡œ: {out_path}")  
#         out_path.write_text(json.dumps(records, ensure_ascii=False, indent=2), encoding="utf-8")

#         processed_files += 1  # â¬…ï¸ íŒŒì¼ ê°œìˆ˜ ì¹´ìš´íŠ¸
#         print(f"âœ” [{parser.__class__.__name__}] file.name: {len(records)} sentences (up to ID {counter-1})")

#     elapsed_time = time.time() - start_time
#     print(f"\nğŸ‰ Done! Total sentences: {counter-1}")
#     print(f"ğŸ“‚ Total processed files: {processed_files}")
#     print(f"â± Total elapsed time: {elapsed_time:.2f} seconds")  # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ í‘œì‹œ

# if __name__ == "__main__":
#     from pathlib import Path

#     # ê²½ë¡œ ì„¤ì • (ìœˆë„ìš° ê²½ë¡œëŠ” r"..." ë˜ëŠ” \\ ì‚¬ìš©)python -m regex_based_doc_parsing.data_parser.processor

#     input_path = Path(r"C:\Users\megan\onestone\BOAZ_Data_preprocess_logics\regex_based_doc_parsing\data_\raw_data\í˜•ì‚¬\set1")
#     output_path = Path(r"C:\Users\megan\onestone\BOAZ_Data_preprocess_logics\regex_based_doc_parsing\data_\sentence_split_json\5.í˜•ì‚¬\set1")


#     # ì‹¤í–‰
#     process_all(input_path, output_path, prefix_code="05")


# --------------------------- openai ë°ì´í„° ì²˜ë¦¬-------------------------------------------------

# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
def process_all(root_folder: Path, output_folder: Path, prefix_code: str = "01") -> None:
    print(root_folder)
    print(root_folder.exists())
    print(root_folder.is_dir())
    print(f"Root folder exists: {root_folder.exists()}, is_dir: {root_folder.is_dir()}")
    print(f"Files found by rglob: {list(root_folder.rglob('*.json'))}")

    start_time = time.time()
    output_folder.mkdir(parents=True, exist_ok=True)

    counter = 1  # ID ë¶€ì—¬ìš©
    processed_files = 0
    
    for file in sorted(root_folder.rglob("*.json")):
        print("Detected file:", file)
        try:
            data = json.loads(file.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {file.name} -> {e}")
            continue
        parser = select_parser(data, str(file.parent))
        records = parser.extract_and_split(data)

        for seq, rec in enumerate(records, start=1):
            rec["id"] = f"sample_{prefix_code}_000_{counter:06d}"
            rec["sequence"] = f"{seq:04d}"

            # ë¬¸ì¥ í´ë¦°ì—…
            rec["sentence"] = re.sub(r"[\r\n\u2028\u2029\u000b\u000c]+", " ", rec["sentence"]).strip()
            rec["sentence"] = re.sub(r"\s{2,}", " ", rec["sentence"])

            counter += 1

        # ì €ì¥
        out_name = file.stem + ".json"
        out_path = output_folder / out_name
        out_path.write_text(json.dumps(records, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {out_path} ({len(records)} sentences)")

        processed_files += 1

    elapsed_time = time.time() - start_time
    print(f"\nğŸ‰ Done! Total sentences: {counter-1}")
    print(f"ğŸ“‚ Total processed files: {processed_files}")
    print(f"â± Total elapsed time: {elapsed_time:.2f} seconds")


if __name__ == "__main__":
    from pathlib import Path
    input_path = Path(r"C:\Users\megan\onestone\BOAZ_Data_preprocess_logics\regex_based_doc_parsing\data_\raw_data\openai")
    output_path = Path(r"C:\Users\megan\onestone\BOAZ_Data_preprocess_logics\regex_based_doc_parsing\data_\sentence_split_json\openai")

    
    process_all(input_path, output_path, prefix_code="01")