# main.py
import json
from pathlib import Path
from typing import List, Dict
from detectors.name_detector import NameDetector
from detectors.address_detector import AddressDetector
from detectors.birth_age_detector import BirthAgeDetector
from detectors.email_detector import EmailDetector
from detectors.personal_id_detector import JuminDetector
from detectors.phone_num_detector import PhoneDetector
from Dict.address_dict import sido_list, sigungu_list, dong_list
from Dict.name_dict import sn1, nn1, nn2, name
from Dict.stopwords_dict import stopwords
import pandas as pd

# ì‚¬ìš©í•  ë””í…í„° ë¦¬ìŠ¤íŠ¸ (í•„ìš”ì— ë”°ë¼ ì£¼ì„ í•´ì œ ë° ì¶”ê°€)
detectors = [
    NameDetector(sn1, nn1, nn2, name,stopwords=stopwords),
    AddressDetector(sido_list, sigungu_list, dong_list),
    BirthAgeDetector(),
    EmailDetector(),
    JuminDetector(),
    PhoneDetector()
    # 
    # ,
]

# detector_label_map.py
DETECTOR_TYPE_MAP = {
    "Name": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì‹ë³„"},
    "Address": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì¤€ì‹ë³„"},
    "BirthAge": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì‹ë³„"},
    "Email": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì‹ë³„"},
    "Jumin": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì‹ë³„"},
    "Phone": {"ê°œì¸/ê¸°ë°€": "ê°œì¸", "ì‹ë³„/ì¤€ì‹ë³„": "ì‹ë³„"},

    # í•„ìš” ì‹œ ë””í…í„° ì¶”ê°€
}


def run_pii_detection(text: str) -> List[Dict]:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ë””í…í„°ë¥¼ ëŒë©° PIIë¥¼ íƒì§€í•˜ê³  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    results = []

    for detector in detectors:
        matches = detector.detect(text) # detect í•˜ëŠ” ë¶€ë¶„
        for m in matches: 
            # detector.score()ì— ë„˜ê¸¸ 'match' ë¬¸ìì—´ì´ ì—†ìœ¼ë©´ ì¶”ì¶œí•´ì„œ ë„£ìŒ
            if "match" not in m: # mì•ˆì— match í‚¤ê°€ ì—†ë‹¤ë©´
                m["match"] = text[m["start"]:m["end"]]  # startë¶€í„° endê¹Œì§€ í† í°ì„ match:í† í° í˜•ì‹ìœ¼ë¡œ ë„£ì–´ë¼

            m["label"] = detector.__class__.__name__.replace("Detector", "") #detector ì´ë¦„ì—ì„œ detectorë§Œ ë¹¼ë©´ AddressDetector -> Address
            m["score"] = detector.score(m["match"])
            results.append(m)

    return results


# âœ… ë³€í™˜ í•¨ìˆ˜: ì›í•˜ëŠ” JSON í¬ë§·ìœ¼ë¡œ ê°€ê³µ
def convert_to_target_format(entry: Dict, results: List[Dict], filename: str, case_field: str, detail_field: str) -> Dict:
    sent_id = entry["id"]
    sentence = entry["sentence"]
    
    # sequenceëŠ” ìˆ«ìë¡œ ë³€í™˜
    sequence = entry.get("sequence")
    if isinstance(sequence, str) and sequence.isdigit():
        sequence = int(sequence)
    elif not isinstance(sequence, int):
        sequence = 0

    return {
        "data": [
            {
                "sentence": sentence,
                "id": sent_id,
                "filename": filename,
                "caseField": case_field,
                "detailField": detail_field,
                "sequence": sequence
            }
        ],
        "annotations": [
            {
                "id": sent_id,
                "annotations": [
                    {
                        "start": r["start"],
                        "end": r["end"],
                        "label": r["label"],
                        "score": r["score"]
                    } for r in results
                ]
            }
        ]
    }


# def process_sentence_split_json(input_folder: Path, output_folder: Path):
#     output_folder.mkdir(parents=True, exist_ok=True)
#     all_rows = [] 

#     for file_path in input_folder.glob("*.json"):
#         print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path.name}")
#         try:
#             data = json.loads(file_path.read_text(encoding="utf-8"))
#             output_list = []

#             for entry in data: # [{entry1},{entry2} ]
#                 sentence = entry["sentence"] #entryì—ì„œ sentence ê°€ì ¸ì™€ì„œ
#                 results = run_pii_detection(sentence) #detection ì§„í–‰
#                 # âœ… CSVìš© ë°ì´í„° ëˆ„ì 
#                 for r in results:
#                     label_type = r["label"]
#                     label_info = DETECTOR_TYPE_MAP.get(label_type, {"ê°œì¸/ê¸°ë°€": "", "ì‹ë³„/ì¤€ì‹ë³„": ""})
#                     all_rows.append({
#                         "ë„ë©”ì¸": detail_field,
#                         "ë‹¨ì–´": r["match"],
#                         "ê°œì¸/ê¸°ë°€": label_info["ê°œì¸/ê¸°ë°€"],
#                         "ì‹ë³„/ì¤€ì‹ë³„": label_info["ì‹ë³„/ì¤€ì‹ë³„"],
#                         "ì •ë³´ ìœ í˜•": r["label"],
#                         "ì ìˆ˜": r.get("score", None),
#                         "ì €ì¥ ê²½ë¡œ": str(file_path)
#                     })
#                 formatted = convert_to_target_format(
#                     entry,
#                     results,
#                     filename=str(file_path),
#                     case_field=case_field,
#                     detail_field=detail_field
#                 )
#                 output_list.append(formatted)

               

#             output_path = output_folder / file_path.name
#             output_path.write_text(json.dumps(output_list, ensure_ascii=False, indent=2), encoding="utf-8")
#             print(f"âœ” ì €ì¥ ì™„ë£Œ: {file_path.name}")

#         except Exception as e:
#             print(f"âŒ ì—ëŸ¬ ë°œìƒ - {file_path.name}: {e}")
    
#     # âœ… DataFrame ì €ì¥
#     df = pd.DataFrame(all_rows)
#     df.to_csv(df_save_path, index=False, encoding="utf-8-sig")
#     print(f"ğŸ§¾ ì „ì²´ CSV ì €ì¥ ì™„ë£Œ â†’ {df_save_path}")

def process_sentence_split_json(input_folder: Path, output_folder: Path):
    output_folder.mkdir(parents=True, exist_ok=True)
    all_rows = [] 

    for file_path in input_folder.glob("*.json"):
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path.name}")
        try:
            data = json.loads(file_path.read_text(encoding="utf-8"))
            output_list = []

            for entry in data:
                sentence = entry["sentence"]
                results = run_pii_detection(sentence)

                for r in results:
                    label_type = r["label"]
                    label_info = DETECTOR_TYPE_MAP.get(label_type, {"ê°œì¸/ê¸°ë°€": "", "ì‹ë³„/ì¤€ì‹ë³„": ""})
                    all_rows.append({
                        "ë„ë©”ì¸": detail_field,
                        "ë‹¨ì–´": r["match"],
                        "ê°œì¸/ê¸°ë°€": label_info["ê°œì¸/ê¸°ë°€"],
                        "ì‹ë³„/ì¤€ì‹ë³„": label_info["ì‹ë³„/ì¤€ì‹ë³„"],
                        "ì •ë³´ ìœ í˜•": r["label"],
                        "ì ìˆ˜": r.get("score", None),
                        "ì €ì¥ ê²½ë¡œ": str(file_path)
                    })

                formatted = convert_to_target_format(
                    entry,
                    results,
                    filename=str(file_path),
                    case_field=case_field,
                    detail_field=detail_field
                )
                output_list.append(formatted)

            output_path = output_folder / file_path.name
            output_path.write_text(json.dumps(output_list, ensure_ascii=False, indent=2), encoding="utf-8")
            print(f"âœ” ì €ì¥ ì™„ë£Œ: {file_path.name}")

        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ - {file_path.name}: {e}")

    # âœ… DataFrame ì €ì¥
    df = pd.DataFrame(all_rows)

    # ì¤€ì‹ë³„ / ê·¸ ì™¸ ë¶„ë¦¬
    df_j = df[df["ì‹ë³„/ì¤€ì‹ë³„"] == "ì¤€ì‹ë³„"]
    df_p = df[df["ì‹ë³„/ì¤€ì‹ë³„"] != "ì¤€ì‹ë³„"]

    base_path = Path("C:/Users/megan/onestone/BOAZ_Data_preprocess_logics/regex_based_doc_parsing/data_/")
    df_j.to_csv(base_path / "output_j.csv", index=False, encoding="utf-8-sig")
    df_p.to_csv(base_path / "output_p.csv", index=False, encoding="utf-8-sig")

    print(f"ğŸ“ output_j.csv â†’ {len(df_j)} rows ì €ì¥ ì™„ë£Œ")
    print(f"ğŸ“ output_p.csv â†’ {len(df_p)} rows ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    print("ğŸš€ PII Detector ì‹œì‘ë¨") 
    input_path = Path("regex_based_doc_parsing/data_/sentence_split_json")
    output_path = Path("regex_based_doc_parsing/data_/pii_detection_output")
    df_save_path = Path("regex_based_doc_parsing/data_/summary.csv")
    # ğŸ”§ caseField, detailFieldëŠ” ì—¬ê¸°ì„œ ì§ì ‘ ì„¤ì • ê°€ëŠ¥
    case_field = "1"
    detail_field = "1"
    
    process_sentence_split_json(input_path, output_path)
